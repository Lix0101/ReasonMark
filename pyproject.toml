[project]
name = "MarkLLM"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "accelerate>=1.5.2",
    "cython>=3.0.12",
    "datasets>=3.5.0",
    "jieba>=0.42.1",
    "matplotlib>=3.10.1",
    "networkx>=3.4.2",
    "nltk>=3.9.1",
    "openai>=1.69.0",
    "pillow>=11.1.0",
    "sacrebleu>=2.5.1",
    "sentence-transformers>=4.0.1",
    "sentencepiece>=0.2.0",
    "tiktoken>=0.9.0",
    "torch>=2.6.0",
    "transformers>=4.50.3",
    "translate>=3.6.1",
    "vllm>=0.8.2",
]

[[tool.uv.index]]
name = "tuna"
url = "https://pypi.tuna.tsinghua.edu.cn/simple"
default = true

[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[tool.uv.sources]
torch = [{ index = "pytorch-cu126", marker = "sys_platform == 'linux'" }]
torchvision = [{ index = "pytorch-cu126", marker = "sys_platform == 'linux'" }]

[dependency-groups]
dev = [
    "ipykernel>=6.29.5",
    "uv>=0.6.10",
]
