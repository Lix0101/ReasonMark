## DISTILLING THE THOUGHT, WATERMARKING THE ANSWER: A PRINCIPLE SEMANTIC GUIDED WATERMARK FOR LARGE REASONING MODELS

<div align="center">
Shuliang Liu<sup>1,2</sup>, Xingyu Li<sup>1</sup>, Hongyi Liu<sup>1</sup>, Yibo Yan<sup>1,2</sup>, Bingchen Duan<sup>1,2</sup>, Qi Zheng<sup>1,2</sup>, Dong Fang<sup>3*</sup>, Lingfeng Su<sup>3</sup>, Xuming Hu<sup>1,2*</sup>
</div>

<div align="center">
<sup>1</sup> The Hong Kong University of Science and Technology (Guangzhou) <br/>
<sup>2</sup> The Hong Kong University of Science and Technology <br/>
<sup>3</sup> Independent Researcher
</div>

<div align="center">
  <a href="https://arxiv.org/abs/2601.05144">
    <img src="https://img.shields.io/badge/arXiv-2601.05144-b31b1b.svg?style=flat" />
  </a>
</div>

## Abstract

Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces **ReasonMark**, a novel watermarking framework specifically designed for reasoning-intensive LLMs. Our approach decouples generation into an undisturbed **Thinking Phase** and a watermarked **Answering Phase**. We propose a **Criticality Score** to identify semantically pivotal tokens from the reasoning trace, which are distilled into a **Principal Semantic Vector (PSV)**. The PSV then guides a semantically-adaptive mechanism that modulates watermark strength based on token-PSV alignment, ensuring robustness without compromising logical integrity. Extensive experiments show ReasonMark surpasses state-of-the-art methods by reducing text Perplexity by 0.35, increasing translation BLEU score by 0.164, and raising mathematical accuracy by 0.67 points. These advancements are achieved alongside a 0.34% higher watermark detection AUC and stronger robustness to attacks, all with a negligible increase in latency. This work enables the traceable and trustworthy deployment of reasoning LLMs in real-world applications.

<div align="center">
  <img src="assert/ReasonMark-onepage3.pdf" alt="ReasonMark overview" width="800">
</div>

---

## ğŸ—ï¸ Project Structure

```
MarkLLM-dev/
â”œâ”€â”€ config/                        # ç®—æ³•é…ç½®ï¼ˆå« config/OURS.jsonï¼‰
â”œâ”€â”€ watermark/
â”‚   â””â”€â”€ ours/                      # OURS/ReasonMark å®ç°ï¼ˆwatermark/ours/ours.pyï¼‰
â”œâ”€â”€ scripts/                       # ç”Ÿæˆ/å¯è§†åŒ–/è´¨é‡/æ£€æµ‹
â”‚   â”œâ”€â”€ generate_hf.sh
â”‚   â”œâ”€â”€ visualize.sh
â”‚   â”œâ”€â”€ assess_quality.sh
â”‚   â””â”€â”€ assess_detectability.sh
â”œâ”€â”€ dataset/                       # è¯„æµ‹æ•°æ®ï¼ˆc4/gsm8k/wmt/human_eval/...ï¼‰
â”œâ”€â”€ outputs/                       # ç”Ÿæˆä¸è¯„æµ‹è¾“å‡ºï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ generate_hf.py                    # ç”Ÿæˆï¼ˆæœ‰æ°´å°/æ— æ°´å°ï¼‰ä¸»å…¥å£
â”œâ”€â”€ assess_detectability.py        # æ£€æµ‹æ€§è¯„ä¼°ä¸»å…¥å£
â”œâ”€â”€ assess_quality.py              # æ–‡æœ¬è´¨é‡è¯„ä¼°ä¸»å…¥å£
â””â”€â”€ visualization.py               # å¯è§†åŒ–ä¸»å…¥å£
```

## ğŸš€ Quick Start

### Prerequisites
- Python **3.10**
- ä¾èµ–ï¼š`torch`ã€`transformers`ã€`vllm`ã€`datasets` ç­‰ï¼ˆè§ `requirements*.txt`ï¼‰

### Installation

```bash
cd MarkLLM-dev

pip install -r requirements.txt
```

---



## ğŸ“Š How to Use (Step-by-step)

### 1) Generate (Watermarked / Unwatermarked)

```bash
# in MarkLLM-dev/

bash scripts/generate_hf.sh \
  --model-path "Qwen/Qwen3-32B" \
  --algorithm-name "OURS" \
  --dataset-name "c4" \
  --dataset-len 200 \
  --watermark-before-think
# å¯¹äº OURS ç®—æ³•, éœ€è¦åŠ ä¸Š --watermark-before-think
```

å¸¸ç”¨å‚æ•°ï¼š

- `--max-model-len`
- `--max-new-tokens` / `--min-new-tokens`
- `--temperature` / `--top-p` / `--top-k` / `--min-p`
- `--watermark-before-think`:åœ¨ `</think>` å‰åº”ç”¨æ°´å°ï¼ˆé€‚é…æ¨ç†æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼‰

### 2) Assess Text Quality

```bash
# in MarkLLM-dev/

bash scripts/assess_quality.sh \
  --algorithm "OURS" \
  --model-path "Llama/Meta-Llama-3.1-70B-bnb-4bit" \
  --dataset-name "c4" \
  --dataset-len 200
```

### 3) Assess Detectability

```bash
# in MarkLLM-dev/

bash scripts/assess_detectability.sh \
  --algorithm "OURS" \
  --model-path "Qwen/Qwen3-32B" \
  --dataset-name "c4" \
  --dataset-len 200 
```


## ğŸ§© Algorithm Configuration (ReasonMark / OURS)

- é…ç½®æ–‡ä»¶ï¼š`config/OURS.json`
- å®ç°ä»£ç ï¼š`watermark/ours/ours.py`

---

## ğŸ“ Dataset

æ•°æ®é›†ä¸ä»»åŠ¡é…ç½®å…¥å£åœ¨ `cfg.py`ï¼Œå¸¸è§åŒ…æ‹¬ï¼š
- `c4`ï¼ˆæ–‡æœ¬ç»­å†™ï¼‰
- `cnn_dailymail`ï¼ˆå†…å®¹æ¦‚æ‹¬ï¼‰
- `wmt16_de_en` / `wmt19_zh_en`ï¼ˆæœºå™¨ç¿»è¯‘ï¼‰
- `human_eval`ï¼ˆä»£ç ç”Ÿæˆï¼‰
- `gsm8k` / `mmlu_pro` / `aime_2025`ï¼ˆæ¨ç†/é€‰æ‹©é¢˜/æ•°å­¦ï¼‰

---

## ğŸ“„ License

æœ¬ä»“åº“æ ¸å¿ƒä»£ç ï¼ˆ`MarkLLM-dev`ï¼‰éµå¾ª **Apache-2.0**ï¼ˆè§ `MarkLLM-dev/LICENSE`ï¼‰ã€‚

---

## ğŸ“– Citation
```bibtex
@article{liu2026distilling,
  title={Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models},
  author={Liu, Shuliang and Li, Xingyu and Liu, Hongyi and Yan, Yibo and Duan, Bingchen and Zheng, Qi and Fang, Dong and Su, Lingfeng and Hu, Xuming},
  journal={arXiv preprint arXiv:2601.05144},
  year={2026}
}
```

## ğŸ“§ Contact

- Email: shulianglyo@gmail.com
